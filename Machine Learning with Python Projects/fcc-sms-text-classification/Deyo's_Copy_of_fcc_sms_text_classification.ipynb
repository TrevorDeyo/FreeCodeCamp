{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "8RZOuS9LWQvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc9ece68-5f7f-431a-caf7-9f0a55a9af99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "#!pip install tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "#!pip install tensorflow\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "lMHwYXHXCar3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d55d01-4718-40b2-9a3c-eeabbb4d7274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The files exist. Skipping downloads\n"
          ]
        }
      ],
      "source": [
        "# get data files\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\"\n",
        "\n",
        "if os.path.exists(train_file_path) and os.path.exists(test_file_path):\n",
        "    print(\"The files exist. Skipping downloads\")\n",
        "else:\n",
        "    print(\"The files do not exist. Downloading...\")\n",
        "    !wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "    !wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "    print(\"Files downloaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "g_h508FEClxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aff8e489-8b92-4e72-d765-d7d6f300bb1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Label                                               Text\n",
            "0         0  ahhhh...just woken up!had a bad dream about u ...\n",
            "1         0                           you can never do nothing\n",
            "2         0  now u sound like manky scouse boy steve,like! ...\n",
            "3         0  mum say we wan to go then go... then she can s...\n",
            "4         0  never y lei... i v lazy... got wat? dat day ü ...\n",
            "...     ...                                                ...\n",
            "4174      0  just woke up. yeesh its late. but i didn't fal...\n",
            "4175      0  what do u reckon as need 2 arrange transport i...\n",
            "4176      1  free entry into our £250 weekly competition ju...\n",
            "4177      1  -pls stop bootydelious (32/f) is inviting you ...\n",
            "4178      0  tell my  bad character which u dnt lik in me. ...\n",
            "\n",
            "[4179 rows x 2 columns]\n",
            "      Label                                               Text\n",
            "0         0  i am in hospital da. . i will return home in e...\n",
            "1         0         not much, just some textin'. how bout you?\n",
            "2         0  i probably won't eat at all today. i think i'm...\n",
            "3         0  don‘t give a flying monkeys wot they think and...\n",
            "4         0                                who are you seeing?\n",
            "...     ...                                                ...\n",
            "1387      0  true dear..i sat to pray evening and felt so.s...\n",
            "1388      0               what will we do in the shower, baby?\n",
            "1389      0  where are you ? what are you doing ? are yuou ...\n",
            "1390      1  ur cash-balance is currently 500 pounds - to m...\n",
            "1391      1  not heard from u4 a while. call 4 rude chat pr...\n",
            "\n",
            "[1392 rows x 2 columns]\n",
            "      Label                                               Text\n",
            "0         0  ahhhh...just woken up!had a bad dream about u ...\n",
            "1         0                           you can never do nothing\n",
            "2         0  now u sound like manky scouse boy steve,like! ...\n",
            "3         0  mum say we wan to go then go... then she can s...\n",
            "4         0  never y lei... i v lazy... got wat? dat day ü ...\n",
            "...     ...                                                ...\n",
            "5566      0  true dear..i sat to pray evening and felt so.s...\n",
            "5567      0               what will we do in the shower, baby?\n",
            "5568      0  where are you ? what are you doing ? are yuou ...\n",
            "5569      1  ur cash-balance is currently 500 pounds - to m...\n",
            "5570      1  not heard from u4 a while. call 4 rude chat pr...\n",
            "\n",
            "[5571 rows x 2 columns]\n",
            "Text files created based on labels.\n"
          ]
        }
      ],
      "source": [
        "# Load Train and Valid TSV files into Pandas dataframes\n",
        "train_df = pd.read_csv(train_file_path, sep='\\t', names=['Label', 'Text'])\n",
        "valid_df = pd.read_csv(test_file_path, sep='\\t', names=['Label', 'Text'])\n",
        "\n",
        "# Encode 'ham' to 1 and 'spam' to 0\n",
        "train_df['Label'] = train_df['Label'].apply(lambda x: 1 if x == 'spam' else 0)\n",
        "valid_df['Label'] = valid_df['Label'].apply(lambda x: 1 if x == 'spam' else 0)\n",
        "\n",
        "print(train_df)\n",
        "print(valid_df)\n",
        "\n",
        "df = pd.concat([train_df, valid_df], axis=0, ignore_index=True)\n",
        "print(df)\n",
        "\n",
        "# Create folders if they don't exist\n",
        "folders = ['train/neg', 'train/pos']\n",
        "for folder in folders:\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "# Iterate through DataFrame and create text files\n",
        "for index, row in df.iterrows():\n",
        "    label = row['Label']\n",
        "    text = row['Text']\n",
        "\n",
        "    label_folder = 'train/neg' if label == 0 else 'train/pos'\n",
        "\n",
        "    file_name = f'{index}.txt'\n",
        "    file_path = os.path.join(label_folder, file_name)\n",
        "\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(text)\n",
        "\n",
        "print(\"Text files created based on labels.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "raw_train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        ")\n",
        "raw_val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        ")\n",
        "\n",
        "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vuy-c6yWjipX",
        "outputId": "07060877-655f-4506-a3b1-95c2da0c1a35"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5571 files belonging to 2 classes.\n",
            "Using 4457 files for training.\n",
            "Found 5571 files belonging to 2 classes.\n",
            "Using 1114 files for validation.\n",
            "Number of batches in raw_train_ds: 140\n",
            "Number of batches in raw_val_ds: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in raw_train_ds.take(1):\n",
        "    for i in range(5):\n",
        "        print(text_batch.numpy()[i])\n",
        "        print(label_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBrOJ6DCj9ar",
        "outputId": "cde9b154-4438-4e28-f038-f2791bf668df"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'the word checkmate in chess comes from the persian phrase shah maat which means; the king is dead.. goodmorning.. have a good day..:)'\n",
            "0\n",
            "b'not yet chikku..wat abt u?'\n",
            "0\n",
            "b'k, wat s tht incident?'\n",
            "0\n",
            "b'free 1st week entry 2 textpod 4 a chance 2 win 40gb ipod or \\xc2\\xa3250 cash every wk. txt pod to 84128 ts&cs www.textpod.net custcare 08712405020.'\n",
            "1\n",
            "b'nite nite pocay wocay luv u more than n e thing 4eva i promise ring u 2morrowxxxx'\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model constants.\n",
        "max_features = 20000\n",
        "embedding_dim = 128\n",
        "sequence_length = 500\n",
        "\n",
        "# vectorization layer. We are using this layer to normalize, split, and map strings to integers\n",
        "vectorize_layer = keras.layers.TextVectorization(\n",
        "    standardize=\"lower\",\n",
        "    max_tokens=max_features,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "# Now that the vectorize_layer has been created, call `adapt` on a text-only dataset\n",
        "\n",
        "# Let's make a text-only dataset (no labels):\n",
        "text_ds = raw_train_ds.map(lambda x, y: x)\n",
        "# Let's call `adapt`:\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "RGhoqjVVKXHC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return vectorize_layer(text), label\n",
        "\n",
        "\n",
        "# Vectorize the data.\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "\n",
        "# Do async prefetching / buffering of the data for best performance on GPU.\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=10)"
      ],
      "metadata": {
        "id": "19SDPjS3R_A9"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A integer input for vocab indices.\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
        "# 'embedding_dim'.\n",
        "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Conv1D + global max pooling\n",
        "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "# We add a vanilla hidden layer:\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
        "\n",
        "model = keras.Model(inputs, predictions)\n",
        "\n",
        "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "w7mf-vcMmifi"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "\n",
        "# Fit the model using the train and test datasets.\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIx0e9amSzA3",
        "outputId": "e239562a-5247-4a82-b11b-c23c34b20de1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "140/140 [==============================] - 29s 195ms/step - loss: 0.3275 - accuracy: 0.8867 - val_loss: 0.0753 - val_accuracy: 0.9758\n",
            "Epoch 2/2\n",
            "140/140 [==============================] - 27s 190ms/step - loss: 0.0660 - accuracy: 0.9827 - val_loss: 0.0392 - val_accuracy: 0.9865\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x795972f11d80>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A string input\n",
        "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "# Turn strings into vocab indices\n",
        "indices = vectorize_layer(inputs)\n",
        "# Turn vocab indices into predictions\n",
        "outputs = model(indices)\n",
        "\n",
        "# Our end to end model\n",
        "end_to_end_model = keras.Model(inputs, outputs)\n",
        "end_to_end_model.compile(\n",
        "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "mM6hSPgkUuor"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "\n",
        "    predict_data = end_to_end_model.predict([pred_text])\n",
        "    predict = [predict_data[0][0]]\n",
        "    if predict_data[0][0] < .5:\n",
        "        predict.append(\"ham\")\n",
        "    else:\n",
        "        predict.append(\"spam\")\n",
        "    return predict\n",
        "pred_text = \"how are you doing today\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qaSYVjWTXKe",
        "outputId": "5515cf88-e618-4298-90de-a22d21423190"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 223ms/step\n",
            "[0.0030478453, 'ham']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Dxotov85SjsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb09260e-fb16-49f9-9ce2-a361eae804fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "[0.0030478453, 'ham']\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "[0.9871975, 'spam']\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "[0.0030447172, 'ham']\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "[0.99958855, 'spam']\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "[0.9996754, 'spam']\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "[0.0030541674, 'ham']\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "[0.0041368036, 'ham']\n",
            "You passed the challenge. Great job!\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    print(prediction) # REMOVE WHEN DONE\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {},
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}